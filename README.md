# 都需要什么
基础材料：

护照
照片
成绩单
证书
雅思成绩单
资金证明

个性化部分：

英文简历
2个推荐信
500个字的个人陈述




# 时间线：
HKU Stastisics，DS：12.1截止第一批。（2025fall统计截止的时间是11.18，offer在1.8，推测2026的offer推迟到1.20左右，因此有可能可以拖到dsml出结果）；
港中文的出结果会很早，如果这几天投递，大概率会比红鸟晚一点点出结果，cs，AI，ASDS；
NUS的mcomp时间太离谱了，作为候补吧。
HKUST的时间也是太晚了，和NUS mcomp同样的问题。

# 拿录取和实习的策略：
10.9投递NUS dsml

10.23之前投递：

HKU Stastistics/DS

港中文：CS/ASDS

结果时间应该是：
红鸟 》 港中文 》 港大 》 NUS


# 上面说的都是宏观的任务，但其实微观上，总结就一句话，改简历。
1.英文的为了申请。建议模块化编辑，用latex，根据不同的专业编造出不同的版本。
2.中文的为了求职（AI产品经理，蚂蚁金融这种也可以）








# 如何最高效的将 CV PS 实习 面试准备 这四项整合到一起？
方法可以选择，对做过的每一个项目深挖，然后发散的对相关的知识进行总结，应对随时到来的面试。


# 从回归分析项目开始

修改方向：

1.加入多模态数据，其中图片是被老师处理好给我的。

2.文本也是一样

文本的内容：一共有两个文本数据：患者描述的症状（家族史，生活习惯，饮食习惯，既往病史），医生的记录（潜在的问题，怀疑的问题）

3.对齐，不仅数据对齐，维度也要对齐（MLP)

为什么要维度对齐，图片数据的维度太大，而标准化的数据只有45个维度，会造成某种形式上的维度失衡，我一开始用了PCA，尝试坍缩到一个更小的维度（45-128自己去验证），但F1只有0.82，说明这个维度选择做的并不好，更换为MLP，效果提升显著。

值得一提的是，数据对齐必须要做，否则不同患者的数据拼接到一起去就乱了。维度对齐不一定要做，做了更好，最好是用attention，但是对算力要求太高，并且在那个时候我还没学到。

4.预测，二分类，用F1分数。
3层MLP，继续进行。（惩罚函数是Relu+dropout）

5.背景是交大附属医院。

# ESG项目

原文：毕马威（KPMG）ESG案例竞赛，团队领队
晋级至半决赛轮（前 8%）。
为某清洁能源科技企业改善其ESG评级从定量的角度提出分析方法并给出建议，基于行业的财务数据和技术型数据训练决策树，神经网络等机器学习模型，最后使用深度学习模型使得交叉验证的预测精度超过65%，识别出涵盖E/S/G三大支柱的5个关键改进指标。

对于在某些指标上表现异常的公司，给予惩罚系数，本质上可以看作对于飘绿行为的一种控制；（注意主语，即我们注意到相关投资机构会对企业的飘绿措施有应对，公司也应该积极迎接挑战，不要让某些指标过高或者过低，触发飘绿的斩杀线。）

（飘绿的2个指标+预测的5个。）      提出了七项可执行措施，包括增设独立董事、优化流动性比率等。


修改方向：ESG投资

对于在某些指标上表现异常的公司，给予惩罚系数，本质上可以看作对于飘绿行为的一种控制；（注意主语，即我们注意到相关投资机构会对企业的飘绿措施有应对，公司也应该积极迎接挑战，不要让某些指标过高或者过低，触发飘绿的斩杀线。）


# 长时间预测的探究大概是这样
以往预测都是用笨逼统计学方法  -------  Transformer出来以后发现更牛逼  ---------  2021年的一篇论文显示Transformer被线性模型击败
我们推测Transformer对于有规律的数据表现好，但是对于无规律的数据表现很差。
我们做了一个验证，证明了这个事情（四个规律性不同的数据集）

引入下一阶段的实验

能不能中和linear和transformer各自的优点？

用了一个叫做反向蒸馏（RDT）的方法

先说正向蒸馏，有一个学生模型，有一个教师模型，正向蒸馏中的学生模型是简单模型而教师模型是复杂模型

但是我们想让Transformer学习Dlinear良好的泛化能力（不过拟合），就要让Dlinear作为教师模型，这就是反向蒸馏（RDT）。

所以我们明白了，transformer预测的loss函数，要分为两部分，即原始的task-only函数，和学习Dlinear的差距函数。

调整二者权重分配，一开始完全学习Dlinear，把它良好的泛化能力学到手，后面降低学习权重，回到transformer，学习更多复杂的细节。

结果统计中包括了：自己，别人，只学别人的，先学别人再学自己的，

可以发现，RDT在MSE上的表现最好。

然后我们尝试解释了一下教师教学生的机制，主要的一个解释是，RDT使得Transformer学习了一些更为规范标准的误差（即Dlinear会识别的误差），而不是去学习一些没有规律的，抽象的误差。验证的方式是，人为加入一些高斯噪声（标准化误差),发现RDT的效果更好了，说明Transformer学习到了更多标准化的误差，更不容易过拟合了。



# Folklore的PRP项目
可以等一等，最后结项会出具一个完整的报告，到时候就看懂了。

构建自动化文本分析流程，利用大语言模型（LLM）对 2,500+ 条跨文化神话母题（motifs）进行提示词工程，重点识别其中的 法律相关语义特征。为增强判定的语义依据，引入 检索增强生成（RAG） 框架，将外部法律文献与指标说明作为上下文，辅助模型在打分时对齐真实制度标准。

```python
from openai import OpenAI
import numpy as np

client = OpenAI()

texts = [
    "Article 1: Everyone is equal before the law.",
    "Article 2: No one shall be arbitrarily deprived of liberty."
]

embeddings = []
for text in texts:
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    embeddings.append(response.data[0].embedding)

print(np.array(embeddings).shape)  # (2, 1536)

```
**此代码讲述了如何把《法律入门》这本书的内容切割成小块，在向量化之后存入数据库**
```python
import faiss
import numpy as np

# 假设 embeddings 已经是 N × 1536 的 numpy 数组
dimension = 1536
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings).astype("float32"))

# 检索一个新问题
query = "human rights law equality"
query_emb = client.embeddings.create(
    model="text-embedding-3-small",
    input=query
).data[0].embedding

D, I = index.search(np.array([query_emb], dtype="float32"), k=3)
print(I)  # 返回最相似的文本索引

```
**这个是讲述在给每一条motif打分的时候，如何先从数据库中检索一段书里的内容作为信息增强，再结合prompt进行打分。**




```python
为进一步提升可靠性，采用 Self-Consistency（SC）方法 对大模型在多次检索与推理下的输出进行集成投票，显著降低了单次打分的随机性。
```
**这个是提示词工程的一部分，可以参考一下实习工作里面的内容**


随后，将提取出的法律语义指标与各国 官方法治发展水平数据 进行稳健回归建模，验证了一个地区神话传说中“含法量”与当前社会法制情况之间的统计相关性。

最后，基于训练得到的回归方程，对缺失官方法律评分的国家进行了 法治水平预测，展现了 LLM 在复杂文本到量化指标映射中的稳定性与应用潜力。




# 国泰君安的缺少一些结论（应该结合一些网上的期货价格分析案例（technical））
和工厂有合作，到工厂去学习了两周，做了一个供应链管理的多目标优化项目。



# Goodyear需要把Yvonne的那个库存预测给弄到手
我觉得可以结合matlab的课程项目 + 工厂的实例

库存预测中做的事情：与运筹部门的同事合作，从生产的角度来考虑，对于优化库存的大目标函数，设计了有关DSI（预测未来的库存能撑的天数）的惩罚项。

简化版本约束是：
**10 <= DSI <= 30**

具体落地到惩罚函数的设计，DSI = 库存/用Transformer预测的未来的需求率 * 天数

其中惩罚函数是：如果DSI<10,触发中等强度的惩罚（只能说是有风险，不一定会真的难以为继），如果DSI<0，触发高强度的惩罚（已经切实影响各方的正常生产和利益关切了）。

而过量生产的惩罚较低，这是因为生产的承载能力摆在那里，概率并不会太大，并且过量生产时，产量本身数值够大，如果惩罚系数再过大，会让方程偏向过量惩罚项而忽略其他项。

总的来说，预期的库存支撑天数要保持在一个合理的范围内，太高造成浪费，太低不能满足生产。


简单介绍几个约束吧：

(a) 需求满足约束

每个工厂在每个时间 t 的需求必须被满足：

(b) 供应能力约束

每个供应商在每个时间 t 的出货量不能超过其能力：


(c) 运输时间约束（如果代码有 shift 或 lag）

如果考虑运输延迟，决策必须在时序上可行。

(d) 非负约束


